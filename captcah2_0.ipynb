{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.导入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.数据集准备"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 标签处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过sklearn的laberlencoder对标签进行处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9,  0, 52, 58, 40, 53, 55, 60, 56,\n",
       "       44, 50, 51, 36, 54, 39, 41, 42, 43, 45, 46, 47, 61, 59, 38, 57, 37,\n",
       "       49, 48, 26, 32, 14, 27, 29, 34, 30, 18, 24, 25, 10, 28, 13, 15, 16,\n",
       "       17, 19, 20, 21, 35, 33, 12, 31, 11, 23, 22], dtype=int64)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_name = '1234567890qwertyuiopasdfghjklzxcvbnmQWERTYUIOPASDFGHJKLZXCVBNM'\n",
    "labels_name = [i for i in labels_name]\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit_transform(labels_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 图片处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将文件夹中的图片转化为Dataset类， \n",
    "1. 如果在初始化的时候传入了transform，则用于测试，输出的值是一个用于测试的列表图片该列表是一个3 30 30 的小图片，5个\n",
    "2. 如果没有，则是用来训练模型的传出的是一个5 2700的矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输出的是一个图片被拆成5个小图片的列表\n",
    "class captcah(Dataset):\n",
    "    def __init__(self, root, transform=None):\n",
    "        self.names = os.listdir('train/train')\n",
    "        self.images = [os.path.join('train/train', image) for image in self.names]\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.images[index]\n",
    "        label = self.names[index][:-4]\n",
    "        \n",
    "        label = [i for i in label]\n",
    "        label = encoder.transform(label)\n",
    "        \n",
    "        image = Image.open(image_path)\n",
    "\n",
    "        # 如果是外部传入的transform的话，就用于测试传出一个用于测试的列表图片\n",
    "        # 该列表是一个3 30 30 的小图片，5个\n",
    "        if self.transform:\n",
    "            data = self.transform(image)\n",
    "            list = []\n",
    "            for i in range(5):\n",
    "                list.append(data[:,:,i * 30 : (i + 1) * 30].reshape(1, -1))\n",
    "            return list, label\n",
    "        \n",
    "        # else 是内部的，如果没有传入transform，就用默认的， 用来训练模型的\n",
    "        # 传出的是一个5 2700的矩阵\n",
    "        else:\n",
    "            trans = transforms.Compose([\n",
    "                transforms.ToTensor(), \n",
    "                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "            \n",
    "            data = trans(image)\n",
    "            list = []\n",
    "            for i in range(5):\n",
    "                list.append(data[:,:,i * 30 : (i + 1) * 30].reshape(1, -1))\n",
    "            \n",
    "            imgs = list[0]\n",
    "            for i in range(4):\n",
    "                imgs = torch.concat((imgs, list[i+1]), axis=0)\n",
    "            return imgs, label\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 数据集准备"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loader准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = captcah('train/train')\n",
    "trainLoader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
    "\n",
    "test_dataset = captcah('train/train', transform=trans)\n",
    "testLoader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.模型训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.1+cpu'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/10, step: 0/2000, loss: 4.128220081329346\n",
      "epoch: 1/10, step: 100/2000, loss: 3.7029056549072266\n",
      "epoch: 1/10, step: 200/2000, loss: 3.142779588699341\n",
      "epoch: 1/10, step: 300/2000, loss: 2.5033583641052246\n",
      "epoch: 1/10, step: 400/2000, loss: 2.329514503479004\n",
      "epoch: 1/10, step: 500/2000, loss: 1.8909507989883423\n",
      "epoch: 1/10, step: 600/2000, loss: 1.6405043601989746\n",
      "epoch: 1/10, step: 700/2000, loss: 1.6601420640945435\n",
      "epoch: 1/10, step: 800/2000, loss: 1.1999495029449463\n",
      "epoch: 1/10, step: 900/2000, loss: 2.0748250484466553\n",
      "epoch: 1/10, step: 1000/2000, loss: 1.6584839820861816\n",
      "epoch: 1/10, step: 1100/2000, loss: 0.7414701581001282\n",
      "epoch: 1/10, step: 1200/2000, loss: 1.2972691059112549\n",
      "epoch: 1/10, step: 1300/2000, loss: 1.4196046590805054\n",
      "epoch: 1/10, step: 1400/2000, loss: 1.2055482864379883\n",
      "epoch: 1/10, step: 1500/2000, loss: 0.8174458146095276\n",
      "epoch: 1/10, step: 1600/2000, loss: 1.2201026678085327\n",
      "epoch: 1/10, step: 1700/2000, loss: 1.1907281875610352\n",
      "epoch: 1/10, step: 1800/2000, loss: 1.0342957973480225\n",
      "epoch: 1/10, step: 1900/2000, loss: 0.8812756538391113\n",
      "epoch: 2/10, step: 0/2000, loss: 1.051773190498352\n",
      "epoch: 2/10, step: 100/2000, loss: 0.8968841433525085\n",
      "epoch: 2/10, step: 200/2000, loss: 0.9000170230865479\n",
      "epoch: 2/10, step: 300/2000, loss: 0.8870688676834106\n",
      "epoch: 2/10, step: 400/2000, loss: 0.6728193759918213\n",
      "epoch: 2/10, step: 500/2000, loss: 0.3874448537826538\n",
      "epoch: 2/10, step: 600/2000, loss: 0.5355814695358276\n",
      "epoch: 2/10, step: 700/2000, loss: 0.597560465335846\n",
      "epoch: 2/10, step: 800/2000, loss: 0.6057401895523071\n",
      "epoch: 2/10, step: 900/2000, loss: 0.5198258757591248\n",
      "epoch: 2/10, step: 1000/2000, loss: 0.652672529220581\n",
      "epoch: 2/10, step: 1100/2000, loss: 0.49092674255371094\n",
      "epoch: 2/10, step: 1200/2000, loss: 0.1990852952003479\n",
      "epoch: 2/10, step: 1300/2000, loss: 0.6489097476005554\n",
      "epoch: 2/10, step: 1400/2000, loss: 0.6831927299499512\n",
      "epoch: 2/10, step: 1500/2000, loss: 0.5891754031181335\n",
      "epoch: 2/10, step: 1600/2000, loss: 0.6562814116477966\n",
      "epoch: 2/10, step: 1700/2000, loss: 0.7057250142097473\n",
      "epoch: 2/10, step: 1800/2000, loss: 0.5891624689102173\n",
      "epoch: 2/10, step: 1900/2000, loss: 0.39705225825309753\n",
      "epoch: 3/10, step: 0/2000, loss: 0.5644670128822327\n",
      "epoch: 3/10, step: 100/2000, loss: 0.3544621765613556\n",
      "epoch: 3/10, step: 200/2000, loss: 0.6099218130111694\n",
      "epoch: 3/10, step: 300/2000, loss: 0.36204174160957336\n",
      "epoch: 3/10, step: 400/2000, loss: 0.6733945608139038\n",
      "epoch: 3/10, step: 500/2000, loss: 0.5531348586082458\n",
      "epoch: 3/10, step: 600/2000, loss: 0.7280406951904297\n",
      "epoch: 3/10, step: 700/2000, loss: 0.1288476139307022\n",
      "epoch: 3/10, step: 800/2000, loss: 0.40344756841659546\n",
      "epoch: 3/10, step: 900/2000, loss: 0.5068943500518799\n",
      "epoch: 3/10, step: 1000/2000, loss: 0.4709094166755676\n",
      "epoch: 3/10, step: 1100/2000, loss: 0.9954920411109924\n",
      "epoch: 3/10, step: 1200/2000, loss: 0.9670420289039612\n",
      "epoch: 3/10, step: 1300/2000, loss: 0.8143582344055176\n",
      "epoch: 3/10, step: 1400/2000, loss: 0.6726998090744019\n",
      "epoch: 3/10, step: 1500/2000, loss: 0.13768132030963898\n",
      "epoch: 3/10, step: 1600/2000, loss: 0.47471562027931213\n",
      "epoch: 3/10, step: 1700/2000, loss: 0.5438580513000488\n",
      "epoch: 3/10, step: 1800/2000, loss: 0.32463350892066956\n",
      "epoch: 3/10, step: 1900/2000, loss: 0.38410958647727966\n",
      "epoch: 4/10, step: 0/2000, loss: 0.3650988042354584\n",
      "epoch: 4/10, step: 100/2000, loss: 0.27409040927886963\n",
      "epoch: 4/10, step: 200/2000, loss: 0.43060100078582764\n",
      "epoch: 4/10, step: 300/2000, loss: 0.42837172746658325\n",
      "epoch: 4/10, step: 400/2000, loss: 0.4397350549697876\n",
      "epoch: 4/10, step: 500/2000, loss: 0.28071328997612\n",
      "epoch: 4/10, step: 600/2000, loss: 0.5670669078826904\n",
      "epoch: 4/10, step: 700/2000, loss: 0.6072707772254944\n",
      "epoch: 4/10, step: 800/2000, loss: 0.2160414159297943\n",
      "epoch: 4/10, step: 900/2000, loss: 1.2861140966415405\n",
      "epoch: 4/10, step: 1000/2000, loss: 0.10537304729223251\n",
      "epoch: 4/10, step: 1100/2000, loss: 0.4992872476577759\n",
      "epoch: 4/10, step: 1200/2000, loss: 0.5095906257629395\n",
      "epoch: 4/10, step: 1300/2000, loss: 0.44223931431770325\n",
      "epoch: 4/10, step: 1400/2000, loss: 0.2517229914665222\n",
      "epoch: 4/10, step: 1500/2000, loss: 0.5764043927192688\n",
      "epoch: 4/10, step: 1600/2000, loss: 0.3185933828353882\n",
      "epoch: 4/10, step: 1700/2000, loss: 0.1801116168498993\n",
      "epoch: 4/10, step: 1800/2000, loss: 0.45231398940086365\n",
      "epoch: 4/10, step: 1900/2000, loss: 0.39909154176712036\n",
      "epoch: 5/10, step: 0/2000, loss: 0.15704555809497833\n",
      "epoch: 5/10, step: 100/2000, loss: 0.26779988408088684\n",
      "epoch: 5/10, step: 200/2000, loss: 0.573980450630188\n",
      "epoch: 5/10, step: 300/2000, loss: 0.5461739301681519\n",
      "epoch: 5/10, step: 400/2000, loss: 0.6393693685531616\n",
      "epoch: 5/10, step: 500/2000, loss: 0.3379226326942444\n",
      "epoch: 5/10, step: 600/2000, loss: 0.5664705038070679\n",
      "epoch: 5/10, step: 700/2000, loss: 0.4021857976913452\n",
      "epoch: 5/10, step: 800/2000, loss: 0.6824980974197388\n",
      "epoch: 5/10, step: 900/2000, loss: 0.517189621925354\n",
      "epoch: 5/10, step: 1000/2000, loss: 0.4580451548099518\n",
      "epoch: 5/10, step: 1100/2000, loss: 0.31356513500213623\n",
      "epoch: 5/10, step: 1200/2000, loss: 0.24209395051002502\n",
      "epoch: 5/10, step: 1300/2000, loss: 0.42462989687919617\n",
      "epoch: 5/10, step: 1400/2000, loss: 0.6875248551368713\n",
      "epoch: 5/10, step: 1500/2000, loss: 0.38140764832496643\n",
      "epoch: 5/10, step: 1600/2000, loss: 0.3185981810092926\n",
      "epoch: 5/10, step: 1700/2000, loss: 1.021793246269226\n",
      "epoch: 5/10, step: 1800/2000, loss: 0.2467755824327469\n",
      "epoch: 5/10, step: 1900/2000, loss: 0.4080051779747009\n",
      "epoch: 6/10, step: 0/2000, loss: 0.11917483061552048\n",
      "epoch: 6/10, step: 100/2000, loss: 0.42434418201446533\n",
      "epoch: 6/10, step: 200/2000, loss: 0.39540934562683105\n",
      "epoch: 6/10, step: 300/2000, loss: 0.10263818502426147\n",
      "epoch: 6/10, step: 400/2000, loss: 0.24925526976585388\n",
      "epoch: 6/10, step: 500/2000, loss: 0.6660235524177551\n",
      "epoch: 6/10, step: 600/2000, loss: 0.6396301984786987\n",
      "epoch: 6/10, step: 700/2000, loss: 0.4022240936756134\n",
      "epoch: 6/10, step: 800/2000, loss: 0.6921447515487671\n",
      "epoch: 6/10, step: 900/2000, loss: 0.6864400506019592\n",
      "epoch: 6/10, step: 1000/2000, loss: 0.2546440660953522\n",
      "epoch: 6/10, step: 1100/2000, loss: 0.24344207346439362\n",
      "epoch: 6/10, step: 1200/2000, loss: 0.16114448010921478\n",
      "epoch: 6/10, step: 1300/2000, loss: 0.06513284891843796\n",
      "epoch: 6/10, step: 1400/2000, loss: 0.5515974760055542\n",
      "epoch: 6/10, step: 1500/2000, loss: 0.0672677680850029\n",
      "epoch: 6/10, step: 1600/2000, loss: 0.30180272459983826\n",
      "epoch: 6/10, step: 1700/2000, loss: 0.4723593592643738\n",
      "epoch: 6/10, step: 1800/2000, loss: 0.16209153831005096\n",
      "epoch: 6/10, step: 1900/2000, loss: 0.09404093027114868\n",
      "epoch: 7/10, step: 0/2000, loss: 0.5409806370735168\n",
      "epoch: 7/10, step: 100/2000, loss: 0.33463600277900696\n",
      "epoch: 7/10, step: 200/2000, loss: 0.12892520427703857\n",
      "epoch: 7/10, step: 300/2000, loss: 0.15535016357898712\n",
      "epoch: 7/10, step: 400/2000, loss: 0.3595941662788391\n",
      "epoch: 7/10, step: 500/2000, loss: 0.27930954098701477\n",
      "epoch: 7/10, step: 600/2000, loss: 0.348998486995697\n",
      "epoch: 7/10, step: 700/2000, loss: 0.41522929072380066\n",
      "epoch: 7/10, step: 800/2000, loss: 0.575685441493988\n",
      "epoch: 7/10, step: 900/2000, loss: 0.5886642336845398\n",
      "epoch: 7/10, step: 1000/2000, loss: 0.33552882075309753\n",
      "epoch: 7/10, step: 1100/2000, loss: 0.5072954297065735\n",
      "epoch: 7/10, step: 1200/2000, loss: 0.31862586736679077\n",
      "epoch: 7/10, step: 1300/2000, loss: 0.46125587821006775\n",
      "epoch: 7/10, step: 1400/2000, loss: 0.24621863663196564\n",
      "epoch: 7/10, step: 1500/2000, loss: 0.28050652146339417\n",
      "epoch: 7/10, step: 1600/2000, loss: 0.30194100737571716\n",
      "epoch: 7/10, step: 1700/2000, loss: 0.35128167271614075\n",
      "epoch: 7/10, step: 1800/2000, loss: 0.22743135690689087\n",
      "epoch: 7/10, step: 1900/2000, loss: 0.1278388649225235\n",
      "epoch: 8/10, step: 0/2000, loss: 0.2741365134716034\n",
      "epoch: 8/10, step: 100/2000, loss: 0.4519495666027069\n",
      "epoch: 8/10, step: 200/2000, loss: 0.4571729898452759\n",
      "epoch: 8/10, step: 300/2000, loss: 0.6056210994720459\n",
      "epoch: 8/10, step: 400/2000, loss: 0.8133598566055298\n",
      "epoch: 8/10, step: 500/2000, loss: 0.3626636564731598\n",
      "epoch: 8/10, step: 600/2000, loss: 0.21247278153896332\n",
      "epoch: 8/10, step: 700/2000, loss: 0.109498530626297\n",
      "epoch: 8/10, step: 800/2000, loss: 0.2516286075115204\n",
      "epoch: 8/10, step: 900/2000, loss: 0.1927281618118286\n",
      "epoch: 8/10, step: 1000/2000, loss: 0.374460369348526\n",
      "epoch: 8/10, step: 1100/2000, loss: 0.4148334860801697\n",
      "epoch: 8/10, step: 1200/2000, loss: 0.3661193549633026\n",
      "epoch: 8/10, step: 1300/2000, loss: 0.09810996800661087\n",
      "epoch: 8/10, step: 1400/2000, loss: 0.5313529372215271\n",
      "epoch: 8/10, step: 1500/2000, loss: 0.32421207427978516\n",
      "epoch: 8/10, step: 1600/2000, loss: 0.10332627594470978\n",
      "epoch: 8/10, step: 1700/2000, loss: 0.10899189859628677\n",
      "epoch: 8/10, step: 1800/2000, loss: 0.2696976959705353\n",
      "epoch: 8/10, step: 1900/2000, loss: 0.14996343851089478\n",
      "epoch: 9/10, step: 0/2000, loss: 0.19999593496322632\n",
      "epoch: 9/10, step: 100/2000, loss: 0.4701714813709259\n",
      "epoch: 9/10, step: 200/2000, loss: 0.7497378587722778\n",
      "epoch: 9/10, step: 300/2000, loss: 0.3270495533943176\n",
      "epoch: 9/10, step: 400/2000, loss: 0.8208075165748596\n",
      "epoch: 9/10, step: 500/2000, loss: 0.13724184036254883\n",
      "epoch: 9/10, step: 600/2000, loss: 0.10896001011133194\n",
      "epoch: 9/10, step: 700/2000, loss: 0.2363455593585968\n",
      "epoch: 9/10, step: 800/2000, loss: 0.5192774534225464\n",
      "epoch: 9/10, step: 900/2000, loss: 0.32210472226142883\n",
      "epoch: 9/10, step: 1000/2000, loss: 0.22019489109516144\n",
      "epoch: 9/10, step: 1100/2000, loss: 0.5250694751739502\n",
      "epoch: 9/10, step: 1200/2000, loss: 0.24014724791049957\n",
      "epoch: 9/10, step: 1300/2000, loss: 0.19382382929325104\n",
      "epoch: 9/10, step: 1400/2000, loss: 0.35932278633117676\n",
      "epoch: 9/10, step: 1500/2000, loss: 0.6421909928321838\n",
      "epoch: 9/10, step: 1600/2000, loss: 0.3738834261894226\n",
      "epoch: 9/10, step: 1700/2000, loss: 0.1788775771856308\n",
      "epoch: 9/10, step: 1800/2000, loss: 0.3636888563632965\n",
      "epoch: 9/10, step: 1900/2000, loss: 0.37021973729133606\n",
      "epoch: 10/10, step: 0/2000, loss: 0.7714833617210388\n",
      "epoch: 10/10, step: 100/2000, loss: 0.14255160093307495\n",
      "epoch: 10/10, step: 200/2000, loss: 0.2866513133049011\n",
      "epoch: 10/10, step: 300/2000, loss: 0.27710166573524475\n",
      "epoch: 10/10, step: 400/2000, loss: 0.30742886662483215\n",
      "epoch: 10/10, step: 500/2000, loss: 0.2785543203353882\n",
      "epoch: 10/10, step: 600/2000, loss: 0.39195024967193604\n",
      "epoch: 10/10, step: 700/2000, loss: 0.9891393780708313\n",
      "epoch: 10/10, step: 800/2000, loss: 0.1575225591659546\n",
      "epoch: 10/10, step: 900/2000, loss: 0.2816086709499359\n",
      "epoch: 10/10, step: 1000/2000, loss: 0.26881757378578186\n",
      "epoch: 10/10, step: 1100/2000, loss: 0.3298113942146301\n",
      "epoch: 10/10, step: 1200/2000, loss: 0.4035186767578125\n",
      "epoch: 10/10, step: 1300/2000, loss: 0.23233135044574738\n",
      "epoch: 10/10, step: 1400/2000, loss: 0.24278458952903748\n",
      "epoch: 10/10, step: 1500/2000, loss: 0.11044088006019592\n",
      "epoch: 10/10, step: 1600/2000, loss: 0.37476077675819397\n",
      "epoch: 10/10, step: 1700/2000, loss: 0.4105345606803894\n",
      "epoch: 10/10, step: 1800/2000, loss: 0.3523513078689575\n",
      "epoch: 10/10, step: 1900/2000, loss: 0.48572659492492676\n",
      "Finish\n"
     ]
    }
   ],
   "source": [
    "class Cap(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super(Cap, self).__init__(*args, **kwargs)\n",
    "        self.fc1 = nn.Linear(3 * 30 * 30, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 128)\n",
    "        self.fc4 = nn.Linear(128, 62)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 2700)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "cap = Cap()\n",
    "n_epochs = 10\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(cap.parameters(), lr=0.003)\n",
    "# bestValLost = float('inf')\n",
    "# earlyStopPatience = 10\n",
    "\n",
    "lossList = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i, data in enumerate(trainLoader):\n",
    "        images, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        output = cap(images)\n",
    "        loss = criterion(output, labels.reshape(-1,).long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 100 == 0:\n",
    "            print(f'epoch: {epoch + 1}/{n_epochs}, step: {i}/{len(trainLoader)}, loss: {loss.item()}')\n",
    "            # lossList.append(loss.item())\n",
    "\n",
    "    # val_loss = loss.item()\n",
    "    # if val_loss < bestValLost:\n",
    "    #     bestValLost = val_loss\n",
    "    #     patience_counters = 0\n",
    "    # else:\n",
    "    #     patience_counters += 1\n",
    "    #     if patience_counters > earlyStopPatience:\n",
    "    #         print('Early stopping triggered. Training stopped.')\n",
    "    #         break\n",
    "    \n",
    "\n",
    "print('Finish')\n",
    "torch.save(cap.state_dict(), 'captcah2_0.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.模型测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试判断函数\n",
    "判断测试传入列表的图片预测值，和所给标签是否相等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def judge(images, labels):\n",
    "    name = []\n",
    "    for i in range(len(images)):\n",
    "        img = images[i].view(1, 2700)\n",
    "        with torch.no_grad():\n",
    "            capts = cap(img)\n",
    "        \n",
    "        ps = torch.exp(capts)\n",
    "        probab = list(ps.numpy()[0])\n",
    "        pre_label = probab.index(max(probab))\n",
    "        name.append(pre_label)\n",
    "    \n",
    "    judgement = (name == list(labels.numpy().reshape(-1,)))\n",
    "    return judgement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型准确率评价"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Images Tested: 100\n",
      "Number of Images Tested: 200\n",
      "Number of Images Tested: 300\n",
      "Number of Images Tested: 400\n",
      "Number of Images Tested: 500\n",
      "Number of Images Tested: 600\n",
      "Number of Images Tested: 700\n",
      "Number of Images Tested: 800\n",
      "Number of Images Tested: 900\n",
      "Number of Images Tested: 1000\n",
      "Number of Images Tested: 1100\n",
      "Number of Images Tested: 1200\n",
      "Number of Images Tested: 1300\n",
      "Number of Images Tested: 1400\n",
      "Number of Images Tested: 1500\n",
      "Number of Images Tested: 1600\n",
      "Number of Images Tested: 1700\n",
      "Number of Images Tested: 1800\n",
      "Number of Images Tested: 1900\n",
      "Number of Images Tested: 2000\n",
      "Number of Images Tested: 2100\n",
      "Number of Images Tested: 2200\n",
      "Number of Images Tested: 2300\n",
      "Number of Images Tested: 2400\n",
      "Number of Images Tested: 2500\n",
      "Number of Images Tested: 2600\n",
      "Number of Images Tested: 2700\n",
      "Number of Images Tested: 2800\n",
      "Number of Images Tested: 2900\n",
      "Number of Images Tested: 3000\n",
      "Number of Images Tested: 3100\n",
      "Number of Images Tested: 3200\n",
      "Number of Images Tested: 3300\n",
      "Number of Images Tested: 3400\n",
      "Number of Images Tested: 3500\n",
      "Number of Images Tested: 3600\n",
      "Number of Images Tested: 3700\n",
      "Number of Images Tested: 3800\n",
      "Number of Images Tested: 3900\n",
      "Number of Images Tested: 4000\n",
      "Number of Images Tested: 4100\n",
      "Number of Images Tested: 4200\n",
      "Number of Images Tested: 4300\n",
      "Number of Images Tested: 4400\n",
      "Number of Images Tested: 4500\n",
      "Number of Images Tested: 4600\n",
      "Number of Images Tested: 4700\n",
      "Number of Images Tested: 4800\n",
      "Number of Images Tested: 4900\n",
      "Number of Images Tested: 5000\n",
      "Number of Images Tested: 5100\n",
      "Number of Images Tested: 5200\n",
      "Number of Images Tested: 5300\n",
      "Number of Images Tested: 5400\n",
      "Number of Images Tested: 5500\n",
      "Number of Images Tested: 5600\n",
      "Number of Images Tested: 5700\n",
      "Number of Images Tested: 5800\n",
      "Number of Images Tested: 5900\n",
      "Number of Images Tested: 6000\n",
      "Number of Images Tested: 6100\n",
      "Number of Images Tested: 6200\n",
      "Number of Images Tested: 6300\n",
      "Number of Images Tested: 6400\n",
      "Number of Images Tested: 6500\n",
      "Number of Images Tested: 6600\n",
      "Number of Images Tested: 6700\n",
      "Number of Images Tested: 6800\n",
      "Number of Images Tested: 6900\n",
      "Number of Images Tested: 7000\n",
      "Number of Images Tested: 7100\n",
      "Number of Images Tested: 7200\n",
      "Number of Images Tested: 7300\n",
      "Number of Images Tested: 7400\n",
      "Number of Images Tested: 7500\n",
      "Number of Images Tested: 7600\n",
      "Number of Images Tested: 7700\n",
      "Number of Images Tested: 7800\n",
      "Number of Images Tested: 7900\n",
      "Number of Images Tested: 8000\n",
      "Number of Images Tested: 8100\n",
      "Number of Images Tested: 8200\n",
      "Number of Images Tested: 8300\n",
      "Number of Images Tested: 8400\n",
      "Number of Images Tested: 8500\n",
      "Number of Images Tested: 8600\n",
      "Number of Images Tested: 8700\n",
      "Number of Images Tested: 8800\n",
      "Number of Images Tested: 8900\n",
      "Number of Images Tested: 9000\n",
      "Number of Images Tested: 9100\n",
      "Number of Images Tested: 9200\n",
      "Number of Images Tested: 9300\n",
      "Number of Images Tested: 9400\n",
      "Number of Images Tested: 9500\n",
      "Number of Images Tested: 9600\n",
      "Number of Images Tested: 9700\n",
      "Number of Images Tested: 9800\n",
      "Number of Images Tested: 9900\n",
      "Number of Images Tested: 10000\n",
      "Number of Images Tested: 10100\n",
      "Number of Images Tested: 10200\n",
      "Number of Images Tested: 10300\n",
      "Number of Images Tested: 10400\n",
      "Number of Images Tested: 10500\n",
      "Number of Images Tested: 10600\n",
      "Number of Images Tested: 10700\n",
      "Number of Images Tested: 10800\n",
      "Number of Images Tested: 10900\n",
      "Number of Images Tested: 11000\n",
      "Number of Images Tested: 11100\n",
      "Number of Images Tested: 11200\n",
      "Number of Images Tested: 11300\n",
      "Number of Images Tested: 11400\n",
      "Number of Images Tested: 11500\n",
      "Number of Images Tested: 11600\n",
      "Number of Images Tested: 11700\n",
      "Number of Images Tested: 11800\n",
      "Number of Images Tested: 11900\n",
      "Number of Images Tested: 12000\n",
      "Number of Images Tested: 12100\n",
      "Number of Images Tested: 12200\n",
      "Number of Images Tested: 12300\n",
      "Number of Images Tested: 12400\n",
      "Number of Images Tested: 12500\n",
      "Number of Images Tested: 12600\n",
      "Number of Images Tested: 12700\n",
      "Number of Images Tested: 12800\n",
      "Number of Images Tested: 12900\n",
      "Number of Images Tested: 13000\n",
      "Number of Images Tested: 13100\n",
      "Number of Images Tested: 13200\n",
      "Number of Images Tested: 13300\n",
      "Number of Images Tested: 13400\n",
      "Number of Images Tested: 13500\n",
      "Number of Images Tested: 13600\n",
      "Number of Images Tested: 13700\n",
      "Number of Images Tested: 13800\n",
      "Number of Images Tested: 13900\n",
      "Number of Images Tested: 14000\n",
      "Number of Images Tested: 14100\n",
      "Number of Images Tested: 14200\n",
      "Number of Images Tested: 14300\n",
      "Number of Images Tested: 14400\n",
      "Number of Images Tested: 14500\n",
      "Number of Images Tested: 14600\n",
      "Number of Images Tested: 14700\n",
      "Number of Images Tested: 14800\n",
      "Number of Images Tested: 14900\n",
      "Number of Images Tested: 15000\n",
      "Number of Images Tested: 15100\n",
      "Number of Images Tested: 15200\n",
      "Number of Images Tested: 15300\n",
      "Number of Images Tested: 15400\n",
      "Number of Images Tested: 15500\n",
      "Number of Images Tested: 15600\n",
      "Number of Images Tested: 15700\n",
      "Number of Images Tested: 15800\n",
      "Number of Images Tested: 15900\n",
      "Number of Images Tested: 16000\n",
      "Number of Images Tested: 16100\n",
      "Number of Images Tested: 16200\n",
      "Number of Images Tested: 16300\n",
      "Number of Images Tested: 16400\n",
      "Number of Images Tested: 16500\n",
      "Number of Images Tested: 16600\n",
      "Number of Images Tested: 16700\n",
      "Number of Images Tested: 16800\n",
      "Number of Images Tested: 16900\n",
      "Number of Images Tested: 17000\n",
      "Number of Images Tested: 17100\n",
      "Number of Images Tested: 17200\n",
      "Number of Images Tested: 17300\n",
      "Number of Images Tested: 17400\n",
      "Number of Images Tested: 17500\n",
      "Number of Images Tested: 17600\n",
      "Number of Images Tested: 17700\n",
      "Number of Images Tested: 17800\n",
      "Number of Images Tested: 17900\n",
      "Number of Images Tested: 18000\n",
      "Number of Images Tested: 18100\n",
      "Number of Images Tested: 18200\n",
      "Number of Images Tested: 18300\n",
      "Number of Images Tested: 18400\n",
      "Number of Images Tested: 18500\n",
      "Number of Images Tested: 18600\n",
      "Number of Images Tested: 18700\n",
      "Number of Images Tested: 18800\n",
      "Number of Images Tested: 18900\n",
      "Number of Images Tested: 19000\n",
      "Number of Images Tested: 19100\n",
      "Number of Images Tested: 19200\n",
      "Number of Images Tested: 19300\n",
      "Number of Images Tested: 19400\n",
      "Number of Images Tested: 19500\n",
      "Number of Images Tested: 19600\n",
      "Number of Images Tested: 19700\n",
      "Number of Images Tested: 19800\n",
      "Number of Images Tested: 19900\n",
      "\n",
      " model Accuary:0.680034001700085\n"
     ]
    }
   ],
   "source": [
    "all_count, correct_count = 0, 0\n",
    "cap.eval()\n",
    "for images, labels in testLoader:\n",
    "    all_count += 1\n",
    "    if judge(images, labels):\n",
    "        correct_count += 1\n",
    "    if all_count % 100 == 0:\n",
    "        print(f'Number of Images Tested: {all_count}')\n",
    "print(f'\\n model Accuary:{correct_count / all_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
